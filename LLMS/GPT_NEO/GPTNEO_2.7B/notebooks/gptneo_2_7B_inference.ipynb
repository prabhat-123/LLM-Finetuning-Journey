{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKGgJcw2Rae",
        "outputId": "5201d5fb-a5ce-4300-ea81-57a1dfe65e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8yGG5CWAriv",
        "outputId": "6a7974d4-acd8-489c-fb6a-4271ee6488e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip freeze"
      ],
      "metadata": {
        "id": "_HOikz0pFr9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Q04qoeynAgZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_lora_model_path = \"/content/gdrive/MyDrive/Generative_AI/GPTNEO2.7B/checkpoint-8962\"\n",
        "model_id=\"EleutherAI/gpt-neo-2.7B\""
      ],
      "metadata": {
        "id": "oYodDhDRBc84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True,\n",
        "                                             torch_dtype = torch.bfloat16,\n",
        "                                             device_map = {\"\":0}\n",
        "                                             )\n"
      ],
      "metadata": {
        "id": "wYaiQu8MCRr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, peft_lora_model_path)"
      ],
      "metadata": {
        "id": "qmyHr8r_FQyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INTRO = \"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request.\"\n",
        "INSTRUCTION_FORMAT = (\n",
        "    \"\"\"{intro}\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: {input}\\n\\n ### Response: \"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "SN8XeImKLDWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(\n",
        "    instruction: str,\n",
        "    input_text: str,\n",
        "    *,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    do_sample: bool = True,\n",
        "    max_new_tokens: int = 512,\n",
        "    top_p: float = 0.92,\n",
        "    top_k: int = 0,\n",
        "    **kwargs,\n",
        ") -> str:\n",
        "    input_ids = tokenizer(\n",
        "        INSTRUCTION_FORMAT.format(\n",
        "            intro=INTRO, instruction=instruction, input=input_text\n",
        "        ),\n",
        "        return_tensors=\"pt\",\n",
        "    ).input_ids\n",
        "    print(input_ids)\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        do_sample=do_sample,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        **kwargs,\n",
        "    )\n",
        "    decoded = tokenizer.batch_decode(gen_tokens)[0]\n",
        "\n",
        "    # The response appears after \"### Response:\".  The model has been trained to append \"### End\" at the end.\n",
        "    m = re.search(r\"#+\\s*Response:\\s*(.+?)#+\\s*End\", decoded, flags=re.DOTALL)\n",
        "\n",
        "    response = None\n",
        "    if m:\n",
        "        response = m.group(1).strip()\n",
        "    else:\n",
        "        # The model might not generate the \"### End\" sequence before reaching the max tokens.  In this case, return\n",
        "        # everything after \"### Response:\".\n",
        "        m = re.search(r\"#+\\s*Response:\\s*(.+)\", decoded, flags=re.DOTALL)\n",
        "        if m:\n",
        "            response = m.group(1).strip()\n",
        "        else:\n",
        "            print(f\"Failed to find response in:\\n{decoded}\")\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "HMiOHZrPLDdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to the response generation program!\")\n",
        "while True:\n",
        "    instruction = \"If you are a doctor, please answer the medical questions based on user's query\"\n",
        "    input_text = input(\"Enter the input text: \")\n",
        "    response = generate_response(\n",
        "        instruction=instruction,\n",
        "        input_text=input_text,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "\n",
        "        max_new_tokens = 100,\n",
        "    )\n",
        "    print('*' * 100)\n",
        "    print(\"Generated Response:\")\n",
        "    print(response)\n",
        "    print('*' * 100)\n",
        "\n",
        "    continue_generation = input(\"Do you want to continue (yes/no)? \").lower()\n",
        "    if continue_generation != \"yes\":\n",
        "        print(\"Exiting the response generation program.\")\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-XltS2ZoLDgS",
        "outputId": "a0540ff8-70f2-47da-b8ee-17a098cb2f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the response generation program!\n",
            "Enter the input text: i am suffering from common cold and a running nose, what should i do for prevention?\n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,  1312,   716,  7195,\n",
            "           422,  2219,  4692,   290,   257,  2491,  9686,    11,   644,   815,\n",
            "          1312,   466,   329, 14196,    30,   628, 44386, 18261,    25,   220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "Yes.  Have cold with running nose are common to occur in a child above 2 years of age. It occurs due to failure of mucosal immunity in your case, and also due to infection with viral infection, and viruses.       Take normal nutritious diet, avoid milk, curd, curd cottage, etc. Also have paracetamol tablets 4 times a day if fever, and cold not better with antibiotics.\n",
            "****************************************************************************************************\n",
            "Do you want to continue (yes/no)? yes\n",
            "Enter the input text: Sunil is my friend\n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,  3825,   346,   318,\n",
            "           616,  1545,   628, 44386, 18261,    25,   220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "Your friend requires physical fitness- it would be a healthy and balanced physical fitness program for himself and thus this should be in harmony with a balanced diet including healthy choices.  For reducing the risk of obesity. Balance on metabolic control will be best with some sort of aerobic and aerobic endurance exercise for about 15 min per day.  Walk and do hill climbs brisk walking or run at a fast pace using the maximal estimated heart rate during your exercise test.  If heart or respiratory rates increase too high, you\n",
            "****************************************************************************************************\n",
            "Do you want to continue (yes/no)? yes\n",
            "Enter the input text: I love Alisha\n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,   314,  1842,   978,\n",
            "         19388,   628, 44386, 18261,    25,   220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "1. Considering your background, you could answer the question as: does age affect the hope? Answer.  2. From where you live and the place that you are looking for you the question Ames below statement and I think you did not wanted to answer. Ask one of Your brothers doctor about the question if he or she believes it.3. I suggest you to answer the question above.4.  if you are a hardcore musician, and close to someone who is a musician (local,\n",
            "****************************************************************************************************\n",
            "Do you want to continue (yes/no)? yes\n",
            "Enter the input text: i have a sore throat, what should i do?\n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,  1312,   423,   257,\n",
            "         19597, 13589,    11,   644,   815,  1312,   466,    30,   628, 44386,\n",
            "         18261,    25,   220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "Hi there, in order to rule out your throat infection, it is helpful to make your throat feel better when it is sore. Another painkiller helps. Take a magnesium supplement once a day and of course, a listerine or peppermint for relief.  You are most likely allergic, especially because you have the sore throat even in the midst of being otherwise well.  Any virus, or any cause will trigger a similar response in you. Good luck!   ...\n",
            "****************************************************************************************************\n",
            "Do you want to continue (yes/no)? yes\n",
            "Enter the input text: i have a severe headache from yesterday and i think like my head will fall infront me \n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,  1312,   423,   257,\n",
            "          6049, 24902,   422,  7415,   290,  1312,   892,   588,   616,  1182,\n",
            "           481,  2121,  1167,  4298,   502,   220,   628, 44386, 18261,    25,\n",
            "           220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "Hi, I am Gop, I am a General Surgeon and I can say that you are definitely having a seizure or something similar and is not usual as usual. Please report yourself to your General Surgeon for best management. Best regards, Gop in General Surgery.  -  Gop  -  Hope these answers help.  -  ChatMedic.   -    -   -    -  -   -   bastard    -\n",
            "****************************************************************************************************\n",
            "Do you want to continue (yes/no)? yes\n",
            "Enter the input text: i want to do a nose surgery can you explain how hard and tough is it gonna be?\n",
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    11, 20312,\n",
            "           351,   281,  5128,   326,  3769,  2252,  4732,    13,   220,   198,\n",
            "         16594,   257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,\n",
            "           198, 21017, 46486,    25,   220,   198,  1532,   345,   389,   257,\n",
            "          6253,    11,  3387,  3280,   262,  3315,  2683,  1912,   319,  2836,\n",
            "           338, 12405,   198,   198, 21017, 23412,    25,  1312,   765,   284,\n",
            "           466,   257,  9686,  8185,   460,   345,  4727,   703,  1327,   290,\n",
            "          5802,   318,   340,  8066,   307,    30,   628, 44386, 18261,    25,\n",
            "           220]])\n",
            "****************************************************************************************************\n",
            "Generated Response:\n",
            "Hello and thank you for trusting the ChatMedic!  A person should do everything in their power to avoid any kind of surgery. And there are some things that should be done, like we need to avoid any infection during any operation and take strong painkillers to avoid any infection.  So it is going to be a big operation but should be a successful one, but you should be careful about anything regarding surgery, so you would be well prepared for this.  Hope I have answered your question!\n",
            "****************************************************************************************************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-818e5cc55765>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcontinue_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Do you want to continue (yes/no)? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontinue_generation\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exiting the response generation program.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7qTNebNLDjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcRKLLoCRS3j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}